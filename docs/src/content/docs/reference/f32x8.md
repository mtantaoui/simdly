---
title: F32x8
description: AVX2 SIMD vector for 8 packed f32 values.
---

# F32x8

AVX2 SIMD vector containing 8 packed f32 values for high-performance vectorized operations.

## Overview

`F32x8` is the primary SIMD vector type in simdly, wrapping Intel's AVX2 `__m256` intrinsic to perform vectorized operations on 8 single-precision floating-point values simultaneously using 256-bit AVX2 instructions.

## Structure

```rust
pub struct F32x8 {
    pub size: usize,        // Number of valid elements (1-8)
    pub elements: __m256,   // AVX2 256-bit vector register
}
```

### Fields

- **`size`**: Number of valid elements in the vector (1-8). Used for partial operations when working with data smaller than 8 elements.
- **`elements`**: The underlying AVX2 256-bit vector register containing 8 packed f32 values.

## Memory Alignment

For optimal performance, data should be aligned to 32-byte boundaries. The structure automatically detects alignment and uses the most efficient load/store operations available.

```rust
use simdly::simd::{Alignment, avx2::f32x8::F32x8};

// Check if pointer is properly aligned
let is_aligned = F32x8::is_aligned(data.as_ptr());
```

## Trait Implementations

### Alignment\<f32>

Provides alignment checking functionality for AVX2 operations.

#### `is_aligned(ptr: *const f32) -> bool`

Checks if a pointer is properly aligned for AVX2 operations (32-byte boundary).

```rust
use simdly::simd::{Alignment, avx2::f32x8::F32x8};

let data = [1.0f32; 8];
let is_aligned = F32x8::is_aligned(data.as_ptr());
```

### SimdLoad\<f32>

Provides various methods for loading data from memory into SIMD vectors.

#### `from_slice(slice: &[f32]) -> Self`

High-level interface for loading f32 data from a slice. Automatically handles partial loads and alignment detection.

```rust
use simdly::simd::{SimdLoad, avx2::f32x8::F32x8};

// Full vector (8 elements)
let data = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
let vec = F32x8::from_slice(&data);

// Partial vector (< 8 elements)
let partial = [1.0, 2.0, 3.0];
let vec = F32x8::from_slice(&partial);

// Oversized array (takes first 8)
let large = [1.0; 16];
let vec = F32x8::from_slice(&large);
```

#### `unsafe fn load(ptr: *const f32, size: usize) -> Self`

Loads exactly 8 elements with automatic alignment detection. Size must be 8.

```rust
use simdly::simd::{SimdLoad, avx2::f32x8::F32x8};

let data = [1.0f32; 8];
let vec = unsafe { F32x8::load(data.as_ptr(), 8) };
```

#### `unsafe fn load_aligned(ptr: *const f32) -> Self`

Loads 8 elements from 32-byte aligned memory (fastest option).

```rust
// Requires 32-byte aligned memory
let vec = unsafe { F32x8::load_aligned(aligned_ptr) };
```

#### `unsafe fn load_unaligned(ptr: *const f32) -> Self`

Loads 8 elements from unaligned memory (slightly slower than aligned).

```rust
let vec = unsafe { F32x8::load_unaligned(data.as_ptr()) };
```

#### `unsafe fn load_partial(ptr: *const f32, size: usize) -> Self`

Loads fewer than 8 elements using masked loading operations (size must be < 8).

```rust
let data = [1.0, 2.0, 3.0];
let vec = unsafe { F32x8::load_partial(data.as_ptr(), 3) };
assert_eq!(vec.size, 3);
```

### SimdStore\<f32>

Provides various methods for storing SIMD vector data to memory.

#### `fn store_at(&self, ptr: *const f32)`

**Status: Unimplemented** - Stores vector data with automatic alignment detection.

#### `unsafe fn stream_at(&self, ptr: *mut f32)`

Non-temporal store that bypasses cache. Requires 32-byte aligned memory.

```rust
use simdly::simd::{SimdStore, avx2::f32x8::F32x8};

let vec = F32x8::from_slice(&data);
unsafe {
    vec.stream_at(aligned_output.as_mut_ptr());
}
```

Best for large datasets where data won't be reused soon.

#### `unsafe fn store_aligned_at(&self, ptr: *mut f32)`

Stores 8 elements to 32-byte aligned memory (fastest option).

```rust
unsafe {
    vec.store_aligned_at(aligned_output.as_mut_ptr());
}
```

#### `unsafe fn store_unaligned_at(&self, ptr: *mut f32)`

Stores 8 elements to unaligned memory (works with any alignment).

```rust
unsafe {
    vec.store_unaligned_at(output.as_mut_ptr());
}
```

#### `unsafe fn store_at_partial(&self, ptr: *mut f32)`

Stores only the valid elements using masked operations. Only stores `self.size` elements.

```rust
let data = [1.0, 2.0, 3.0];
let vec = F32x8::from_slice(&data);  // size = 3

let mut output = [0.0f32; 8];
unsafe {
    vec.store_at_partial(output.as_mut_ptr());
}
// Only first 3 elements are written
```

## Usage Examples

### Basic Operations

```rust
use simdly::simd::{SimdLoad, SimdStore, avx2::f32x8::F32x8};

// Load data
let input = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
let vec = F32x8::from_slice(&input);

// Store data
let mut output = [0.0f32; 8];
unsafe {
    vec.store_unaligned_at(output.as_mut_ptr());
}

assert_eq!(output, input);
```

### Partial Operations

```rust
use simdly::simd::{SimdLoad, SimdStore, avx2::f32x8::F32x8};

// Load partial data
let input = [1.0, 2.0, 3.0];
let vec = F32x8::from_slice(&input);
assert_eq!(vec.size, 3);

// Store partial data
let mut output = [0.0f32; 8];
unsafe {
    vec.store_at_partial(output.as_mut_ptr());
}

assert_eq!(&output[..3], &input);
assert_eq!(&output[3..], &[0.0; 5]);
```

### Aligned Memory Operations

```rust
use simdly::simd::{Alignment, SimdLoad, SimdStore, avx2::f32x8::F32x8};
use std::alloc::{alloc, dealloc, Layout};

// Allocate aligned memory
let layout = Layout::from_size_align(8 * std::mem::size_of::<f32>(), 32).unwrap();
let aligned_ptr = unsafe { alloc(layout) as *mut f32 };

// Verify alignment
assert!(F32x8::is_aligned(aligned_ptr));

// Use aligned operations
let data = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
unsafe {
    std::ptr::copy_nonoverlapping(data.as_ptr(), aligned_ptr, 8);
    
    let vec = F32x8::load_aligned(aligned_ptr);
    vec.store_aligned_at(aligned_ptr);
}

// Clean up
unsafe { dealloc(aligned_ptr as *mut u8, layout) };
```

### Processing Arrays

```rust
use simdly::simd::{SimdLoad, SimdStore, avx2::f32x8::F32x8};

fn process_array(input: &[f32]) -> Vec<f32> {
    let mut output = vec![0.0; input.len()];
    
    // Process full chunks
    for (i, chunk) in input.chunks_exact(8).enumerate() {
        let vec = F32x8::from_slice(chunk);
        
        // Your SIMD operations here...
        
        unsafe {
            vec.store_unaligned_at(output[i * 8..].as_mut_ptr());
        }
    }
    
    // Handle remainder
    let remainder_start = (input.len() / 8) * 8;
    if remainder_start < input.len() {
        let remainder_size = input.len() - remainder_start;
        let vec = F32x8::from_slice(&input[remainder_start..]);
        
        // Your SIMD operations here...
        
        unsafe {
            vec.store_at_partial(output[remainder_start..].as_mut_ptr());
        }
    }
    
    output
}
```

## Performance Considerations

1. **Memory Alignment**: Use 32-byte aligned memory when possible for optimal performance
2. **Batch Processing**: Process data in chunks that match SIMD vector sizes (8 elements)
3. **Target Features**: Enable AVX2 during compilation with `-C target-feature=+avx2`
4. **Streaming Stores**: Use `stream_at()` for large datasets that won't be reused

## Safety Notes

- All load and store operations (except `from_slice()` and `store_at()`) are unsafe
- Pointers must point to valid memory with sufficient space
- Aligned operations require proper memory alignment
- Always verify pointer validity before use

## Related

- [SimdLoad trait](/reference/simd-load/) - Loading operations
- [SimdStore trait](/reference/simd-store/) - Storing operations  
- [Alignment trait](/reference/alignment/) - Alignment checking